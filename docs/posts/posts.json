[
  {
    "path": "posts/2021-03-15-project-sample-a/",
    "title": "Project Sample A",
    "description": "An exploration of cetacean species richness on the California coast.",
    "author": [
      {
        "name": "Taylor",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [],
    "contents": "\r\n\r\n\r\nShow code\r\n\r\n# Read in the data all together\r\nspecies <- here(\"data\",\"ca_cetaceans\", \"ca_cetaceans\")\r\nspecies_files <- dir(species, full.names = TRUE, pattern = \"*.tif\")\r\n\r\n# Rasterize all these files together using raster::stack\r\ncetaceans_data <- raster::stack(species_files)\r\n\r\n# Write a function to determine if species are present in a cell, with a threshold of 0.6 meaning \"present\"\r\nis_present <- function(x, thresh = .6){\r\n  y <- ifelse(x >= thresh, 1, 0)\r\n  return(y)\r\n}\r\n\r\n# Apply the threshold function to our stack\r\nspecies_richness <- calc(cetaceans_data, fun = is_present)\r\n\r\n# Find out how many species are in each cell\r\nspecies_richness1 <- calc(species_richness, fun = sum, na.rm = TRUE)\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\n# Now create the file to use for the CA coastline\r\n\r\nstates <- ne_download(scale = 110, type = \"states\", category = \"cultural\", returnclass = \"sf\")\r\n\r\nca_state <- states %>% \r\n  filter(name == \"California\")\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\n# Crop the species raster to match the CA coastline\r\nspecies_raster_cropped <- crop(species_richness1, extent(ca_state))\r\n\r\n# Now turn this cropped raster into a dataframe\r\nspecies_richness_df <- raster::rasterToPoints(species_raster_cropped) %>%\r\n  as.data.frame() %>% \r\n  filter(layer != 0) # Filter out cells that have no data in them\r\n\r\n# Now we have the species richness dataframe with which to make our ggplot!\r\n\r\n\r\n\r\n\r\n\r\nShow code\r\n\r\n# Now plot everything together\r\n\r\nggplot()+\r\n  geom_raster(data = species_richness_df, aes(x = x, y = y, fill = layer))+\r\n  geom_sf(data = ca_state, fill = \"lemonchiffon2\")+\r\n  scale_fill_gradient(low = \"white\", high = \"mediumblue\", name = \"Likely number of cetacean species present\")+\r\n  theme_minimal()+\r\n  theme(panel.background = element_rect(fill = \"grey90\"))+\r\n  labs( x = \"Longitude\",\r\n        y = \"Latitude\",\r\n        title = \"Cetacean species richness on the California coast\")\r\n\r\n\r\n\r\n\r\nFigure 1: Map of species richness of cetaceans off the coast of California. Species richness is defined as the number of species likely to be present in a certain area. For a species to be considered “present,” a likelihood threshold of 0.6 was observed, meaning that there had to be a minimum 60% chance that a species would be present in order for it to be considered “present” in our analysis.\r\nNote: I purposely did not clip the extent of the map because I liked the aesthetics of seeing the whole state shape rather than just the extent covered by the species raster. To clip I would have inserted a line in my ggplot of coord_sf(xlim = c(-125, -115), ylim = c(32, 38)).\r\nSources:\r\nKaschner, K., Rius-Barile, J., Kesner-Reyes, K., Garilao, C., Kullander, S., Rees, T., & Froese, R. (2016). AquaMaps: Predicted range maps for aquatic species. www.aquamaps.org\r\nMade with Natural Earth. Free vector and raster map data @ naturalearthdata.com.\r\nEnd Project Sample A\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-15-project-sample-a/project-sample-a_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2022-04-20T14:39:36-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-15-project-sample-b/",
    "title": "Project Sample B",
    "description": "Using binary logistic regression to test the feasibility of using plant height, canopy length, canopy width, and number of green leaves to determine species of palmetto.",
    "author": [
      {
        "name": "Taylor",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [],
    "contents": "\r\n\r\n\r\nhide\r\n\r\n# Read in data\r\n\r\npalmetto_data <- read_csv(here(\"data\", \"palmetto.csv\"), \r\n                          col_types = cols(.default = 'c')) %>% \r\n  mutate(height = as.numeric(height)) %>% \r\n  mutate(length = as.numeric(length)) %>% \r\n  mutate(width = as.numeric(width)) %>% \r\n  mutate(green_lvs = as.numeric(green_lvs))\r\n\r\n\r\n\r\nOverview\r\nThis report evaluates data on two palmetto species, and uses binary logistic regression to test the feasibility of using certain indicator variables (tree height, canopy length, canopy width, and number of green leaves) to determine the trees’ species. Species 1 represents Serenoa repens, while Species 2 represents Sabal etonia. For the purposes of this analysis, I will be simply referring to them as “Species 1” and “Species 2” respectively unless stated otherwise.\r\nData source: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5\r\nResults\r\n1. Exploratory Visualizations\r\nPrinciple Components Analysis (PCA)\r\n\r\n\r\nhide\r\n\r\n# Make PCA subset\r\n\r\npalmetto_pca <- palmetto_data %>% \r\n  select(height, length, width, green_lvs) %>% \r\n  drop_na() %>% \r\n  scale() %>% \r\n  prcomp()\r\n\r\n# Make another subset for labeling\r\npalmetto_complete <- palmetto_data %>% \r\n  drop_na(height, length, width, green_lvs)\r\n\r\n# Make PCA biplot\r\n\r\nautoplot(palmetto_pca,\r\n         data = palmetto_complete,\r\n         colour = \"species\",\r\n         size = 1,\r\n         alpha = 0.7,\r\n         loadings = TRUE,\r\n         loadings.label = TRUE)+\r\n  scale_color_manual(values = c(\"goldenrod\", \"forestgreen\"))+\r\n  theme_bw()\r\n\r\n\r\n\r\n\r\nFigure 1: PCA biplot of our palmetto data. Principle component 1 (PC1) accounts for ~69% of variance in our data, and principle component 2 (PC2) accounts for ~20% of the variance in our data.\r\nKey takeaways:\r\nFrom our biplot, we can see the number of green leaves on a tree and the length of canopy have almost no correlation, as their loadings are at approximately 90 degrees to each other.\r\nTree height, canopy width, and canopy length all appear to be closely (positively) correlated, as they are loaded closely together.\r\nAdditionally, it appears the two species begin to diverge in similarity along increasing PC1.\r\nTree Height vs. Canopy Length\r\n\r\n\r\nhide\r\n\r\n# Other dataviz\r\n\r\nggplot(data = palmetto_data, aes(x = length, y = height))+\r\n  geom_point(aes(color=species), alpha = 0.7)+\r\n  scale_color_manual(values = c(\"goldenrod\", \"forestgreen\"))+\r\n  theme_bw()+\r\n  labs(x = \"Canopy Length\",\r\n       y = \"Height\")\r\n\r\n\r\n\r\n\r\nFigure 2: Height of trees vs. canopy length.\r\nKey takeaways:\r\nWe can see that in both species, canopy length generally increases with increasing tree height.\r\nHowever, Species 2 seems to tend to have a lower height overall.\r\n2. Binary Logistic Regression\r\nVariables:\r\nTree height (cm)\r\nCanopy length (cm)\r\nCanopy width(cm)\r\nNumber of green leaves\r\nFor this evaluation, our “0” reference level is Species 1, or Serenoa repens. Since a binary logistic regression calculates the probability of the non-zero factor, this indicates that our output will evaluate the probability that an observation is Species 2, or Sabal etonia.\r\n\r\n\r\nhide\r\n\r\n# Make a subset with our species numbers as factors. \r\n\r\npalmetto_blr_data <- palmetto_complete %>% \r\n  mutate(species = as.factor(species))\r\n\r\n# Double check the factor levels, and we see that \"Species 1\" is our 0 reference level. So left-hand side of equation will be probability of SPECIES 2.\r\n\r\npalmetto_blr <- glm(species ~ height + length + width + green_lvs,\r\n                    data = palmetto_blr_data,\r\n                    family = \"binomial\")\r\n\r\ntidy_palmetto_blr <- broom::tidy(palmetto_blr)\r\n\r\nfinal_palmetto_blr <- tidy_palmetto_blr %>% \r\n  mutate(p.value=case_when(p.value <= 0.0001 ~ \"<0.0001\"))\r\n\r\nkbl(\r\n  final_palmetto_blr,\r\n  col.names = c(\"Predictor Variable\", \"Coefficient\", \"Std. Error\", \"Statistic\", \"p-value\"),\r\n  align = c(\"l\", \"c\", \"c\", \"c\", \"c\"),\r\n   digits = 3,\r\n  caption = \"Table 1: Results of binary linear regression on palmetto data.\") %>% \r\n  kable_styling(bootstrap_options = \"striped\",\r\n                full_width = F)\r\n\r\n\r\n\r\nTable 1: Table 1: Results of binary linear regression on palmetto data.\r\n\r\n\r\nPredictor Variable\r\n\r\n\r\nCoefficient\r\n\r\n\r\nStd. Error\r\n\r\n\r\nStatistic\r\n\r\n\r\np-value\r\n\r\n\r\n(Intercept)\r\n\r\n\r\n3.227\r\n\r\n\r\n0.142\r\n\r\n\r\n22.712\r\n\r\n\r\n<0.0001\r\n\r\n\r\nheight\r\n\r\n\r\n-0.029\r\n\r\n\r\n0.002\r\n\r\n\r\n-12.670\r\n\r\n\r\n<0.0001\r\n\r\n\r\nlength\r\n\r\n\r\n0.046\r\n\r\n\r\n0.002\r\n\r\n\r\n24.556\r\n\r\n\r\n<0.0001\r\n\r\n\r\nwidth\r\n\r\n\r\n0.039\r\n\r\n\r\n0.002\r\n\r\n\r\n18.782\r\n\r\n\r\n<0.0001\r\n\r\n\r\ngreen_lvs\r\n\r\n\r\n-1.908\r\n\r\n\r\n0.039\r\n\r\n\r\n-49.107\r\n\r\n\r\n<0.0001\r\n\r\n\r\n3. Success of Regression Model\r\n\r\n\r\nhide\r\n\r\n# What are the actual probabilities of being Species 2 for each of the existing observations in our palmetto_complete data frame?\r\n\r\n# Create the fitted blr - probability that an observation is Species 2.\r\n\r\nblr_fitted <- palmetto_blr %>% \r\n  broom::augment(type.predict = \"response\")\r\n\r\n# Wrangle this dataset into something usable for an output\r\n\r\nblr_correct <- blr_fitted %>% \r\n  mutate(predicted = case_when(.fitted >= 0.50 ~ 2,\r\n                               .fitted <= 0.50 ~ 1)) %>% \r\n  mutate(correct = case_when(predicted == species ~ \"Correct\",\r\n                             TRUE ~ \"Incorrect\")) %>% \r\n  mutate(species = case_when(species == 1 ~ \"Serenoa repens\",\r\n                             species == 2 ~ \"Sabal etonia\")) %>%\r\n  select(species, .fitted, predicted, correct) %>% \r\n  group_by(species, correct) %>% \r\n  summarize(number_correct = n()) %>% \r\n  pivot_wider(names_from = correct, values_from = number_correct) %>%\r\n  mutate(Percent_Correct = (Correct/(Incorrect+Correct)*100))\r\n\r\n# Now make it pretty!\r\n\r\nkbl(\r\n  blr_correct,\r\n  col.names = c(\"Species\", \"Correctly Classified\", \"Incorrectly Classified\", \"Percent Correctly Classified\"),\r\n  digits = 3,\r\n  align = c(\"l\", \"c\", \"c\", \"c\"),\r\n  caption =  \"Table 2: Successful prediction of species by binary linear regression on palmetto data.\") %>% \r\n  kable_styling(bootstrap_options = \"striped\",\r\n                full_width = F) \r\n\r\n\r\n\r\nTable 2: Table 2: Successful prediction of species by binary linear regression on palmetto data.\r\n\r\n\r\nSpecies\r\n\r\n\r\nCorrectly Classified\r\n\r\n\r\nIncorrectly Classified\r\n\r\n\r\nPercent Correctly Classified\r\n\r\n\r\nSabal etonia\r\n\r\n\r\n5701\r\n\r\n\r\n454\r\n\r\n\r\n92.624\r\n\r\n\r\nSerenoa repens\r\n\r\n\r\n5548\r\n\r\n\r\n564\r\n\r\n\r\n90.772\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-15-project-sample-b/project-sample-b_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-04-20T14:39:36-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-15-project-sample-c/",
    "title": "Project Sample C",
    "description": "Using multicriteria analysis (MCA) to determine priority watersheds for conservation in southern Santa Barbara County.",
    "author": [
      {
        "name": "Taylor",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [],
    "contents": "\r\nUsing MCA to determine priority watersheds for conservation\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-04-20T14:39:37-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-15-project-sample-d/",
    "title": "Project Sample D",
    "description": "Principle components analysis (PCA) of nutritional values of breakfast cereals.",
    "author": [
      {
        "name": "Taylor",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [],
    "contents": "\r\nIntroduction\r\nThis analysis examines the relationships between major nutritional values of breakfast cereals produced by major manufacturers General Mills Inc., Kellogg Co., Post Foods LLC, and the Quaker Oats Co. These manufacturers were chosen as they are the largest producers of breakfast cereals by sales. Nutritional data is provided by the USDA FoodData Central. The major nutritional values explored are kcal, protein, fat, carbs, sugar, and fiber content, in accordance with FDA guidance.\r\nSource: https://fdc.nal.usda.gov/index.html\r\nWrangling and PCA\r\n1. Wrangle data\r\n\r\n\r\n# Read in the data we're using, then clean it up a bit.\r\n\r\nusda_nutrients <- read.csv(here(\"data\", \"usda_nutrients.csv\")) %>% \r\n  clean_names() %>% \r\n  mutate(across(where(is.character), tolower))\r\n\r\n# Create a subset of only the data we will be using - in this case, breakfast cereals. We will be comparing the major nutrient values: kcal, protein, carbs, fat, sugar and fiber.\r\n\r\ncereals_nutrients <- usda_nutrients %>% \r\n  filter(food_group == \"breakfast cereals\") %>% # Select for breakfast cereals.\r\n  filter(mfg_name %in% c(\"kellogg, co.\", \"the quaker oats, co.\", \"general mills inc.\", \"post foods, llc\")) # Select specifically for the four brands we are evaluating. \r\n\r\n\r\n\r\n2. PCA\r\n\r\n\r\n# Now write the code for PCA with the dataset we created above.\r\n\r\ncereals_pca <- cereals_nutrients %>% # Create a pca dataset starting with the cereals subset we created above.\r\n  select(energy_kcal, ends_with(\"_g\")) %>% # Select the variables we will be performing PCA for\r\n  drop_na() %>% # Drop any NA values \r\n  scale() %>% # Scale the values, since they are not all measured in the same units\r\n  prcomp() # Principle components\r\n\r\ncereals_complete <- cereals_nutrients %>% \r\n  drop_na(energy_kcal, ends_with(\"_g\")) # Create a dataset to pull from, then drop observations with NA for our variables of interest.\r\n\r\nautoplot(cereals_pca,\r\n         data = cereals_complete, # Use this dataset to create aesthetics\r\n         colour = 'mfg_name',\r\n         loadings = TRUE, # Add loadings arrows\r\n         loadings.label = TRUE,\r\n         loadings.colour = \"black\",\r\n         loadings.label.colour = \"black\",\r\n         loadings.label.vjust = -0.5)+\r\n  theme_minimal()+\r\n  scale_x_continuous(expand = c(0.05,0.05))+ # Expand limits so we can read the arrow labels\r\n  scale_color_manual(labels = c(\"General Mills\", \"Kellogg\", \"Post Foods\", \"Quaker Oats\"), values = c(\"cornflowerblue\", \"coral\", \"forestgreen\", \"darkblue\"))+\r\n  labs(colour = \"Manufacturer\")\r\n\r\n\r\n\r\n\r\nFigure 1: Biplot depicting principle component analysis (PCA) of six different nutritional variables among breakfast cereals produced by four different manufacturers.\r\nSummary\r\nFrom the above Principle Component Analysis and biplot, we can draw the following takeaways:\r\nFiber and protein content appear most closely correlated, as these arrows are closest together, thus indicating that the variance explained by these variables are similar.\r\nSugar and fiber content have a negative correlation in breakfast cereals, as the angle between their arrows is much larger than 90 degrees and thus nearly opposite.\r\nProtein and fiber content have a slight negative loading value on Principle Component 1 (PC1), while fat, kcal, carb and sugar content all have a positive loading value on PC1.\r\nSugar content has the only positive loading value on Principle Component 2 (PC2), while all other variables have a negative loading value on PC2.\r\nHowever, upon adding the variances explained by PC1 and PC2, we see that this biplot only explains approximately 61.75% of variance among the data we are evaluating. This indicates that further analysis and consideration is needed to confidently evaluate correlation between variables in this data set.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-15-project-sample-d/project-sample-d_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-04-20T14:39:37-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-15-project-sample-e/",
    "title": "Project Sample E",
    "description": "Wordcloud and sentiment analysis of one of my favorite books!",
    "author": [
      {
        "name": "Taylor",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [],
    "contents": "\r\n\r\n\r\nShow code\r\n\r\n# Read in the pdf\r\neragon_text <- pdf_text(here(\"data\", \"Eragon.pdf\"))\r\n\r\n\r\n\r\n1. Wordcloud of Eragon text\r\n\r\n\r\nShow code\r\n\r\n# make the data tidy\r\neragon_tidy <- data.frame(eragon_text) %>% \r\n  mutate(text_full = str_split(eragon_text, pattern = \"\\\\n\")) %>% \r\n  unnest(text_full)%>% \r\n  mutate(text_full = str_trim(text_full))\r\n\r\n# Make it into a dataframe\r\neragon_df <- eragon_tidy %>% \r\n  slice(-(1:12))\r\n\r\n# Create tokens\r\neragon_tokens <- eragon_df %>% \r\n  unnest_tokens(word, text_full) %>% \r\n  dplyr::select(-eragon_text)\r\n\r\n# Add up the wordcounts\r\neragon_wordcount <- eragon_tokens %>% \r\n  count(word)\r\n\r\n# Remove all stopwords\r\neragon_nonstopwords<- eragon_tokens %>% \r\n  anti_join(stop_words, by = \"word\")\r\n\r\n# Make a subset with counts of only non-stopwords\r\nnon_stop_counts <- eragon_nonstopwords %>% \r\n  count(word) %>% \r\n  filter(!(str_detect(word, \"\\\\d\"))) # Use this line to remove all rows of numbers\r\n\r\n# Make a subset for a wordcloud!\r\neragon_top100 <- non_stop_counts %>% \r\n  arrange(-n) %>% \r\n  filter(word != \"eragon\") %>% \r\n  filter(word != \"brom\") %>%\r\n  filter(word != \"murtagh\") %>%\r\n  filter(word != \"saphira\") %>%\r\n  slice(1:100)\r\n\r\n# Read in data for background:\r\negg_img <- readJPEG(here(\"data\", \"egg2.jpg\"))\r\n\r\n# Make a wordcloud!\r\neragon_cloud <- ggplot(data = eragon_top100, aes(label = word, color = n))+\r\n  annotation_custom(rasterGrob(egg_img,\r\n                               width = unit(1, \"npc\"),\r\n                               height = unit(1, \"npc\")),\r\n                    -Inf, Inf, -Inf, Inf)+\r\n  geom_text_wordcloud(aes(size =  n))+\r\n  scale_color_gradient(low = \"green\", high = \"white\")+\r\n  scale_size_area(max_size = 10)\r\n\r\neragon_cloud\r\n\r\n\r\n\r\n\r\nImage 1: Illustrated word cloud for the entire text of Eragon (excluding main character names). Apologies for the low quality background image, I refused to use a screenshot from the movie.\r\n2. Sentiment analysis of Eragon\r\n\r\n\r\nShow code\r\n\r\n# Perform sentiment analysis using nrc\r\n\r\neragon_nrc <- eragon_nonstopwords %>%\r\n  inner_join(get_sentiments(\"nrc\"), by = \"word\")\r\n\r\neragon_nrc_counts <- eragon_nrc %>% \r\n  count(sentiment)\r\n  \r\n\r\nggplot(data = eragon_nrc_counts, aes(reorder(sentiment, -n),n), fill = sentiment)+\r\n  geom_col(aes(fill = sentiment))+\r\n  coord_flip()+\r\n  theme_bw()+\r\n  labs(x = \"Sentiment\",\r\n       y = \"Count\")+\r\n  scale_fill_brewer(palette = \"Set3\")+\r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\nImage 2: Sentiment analysis of the entire Eragon text. We can see that “negative,” “positive,” and “fear” are the sentiments with the highest counts in the book, while “disgust” and “surprise” are both close in last place.\r\nSource: Paolini, C. (2003). Eragon. New York: Alfred A. Knopf. Accessed through Academia.edu\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-15-project-sample-e/project-sample-e_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2022-04-20T14:39:37-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-09-welcome/",
    "title": "Welcome",
    "description": {},
    "author": [
      {
        "name": "Taylor",
        "url": {}
      }
    ],
    "date": "2021-02-09",
    "categories": [],
    "contents": "\r\nHere is my first ever blog post, where I talk about all things sourdough, plants, and data analysis.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-04-20T14:39:36-07:00",
    "input_file": {}
  }
]
